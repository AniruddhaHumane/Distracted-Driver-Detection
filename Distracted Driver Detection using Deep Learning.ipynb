{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distracted Driver Detection using deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aniruddha Humane  4321\n",
    "#### Neha Prabhune         4341\n",
    "#### Vasanti Sathe            4347 \n",
    "\n",
    "#### Guide - Prof. D. T. Mane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a very small neural network from scratch due to limited time\n",
    "###### Details of neural network\n",
    "\n",
    "#### Input layer\n",
    "- no of neurons = no of pixels = 3x150x150 = 64500 neurons\n",
    "\n",
    "#### Convolutional layer\n",
    "- 32 filters (3x3)\n",
    "- input (3*150*150)\n",
    "- Activation: ReLU\n",
    "- input no of neurons = 64500 neurons\n",
    "- output no of neurons = no of filters = 32\n",
    "\n",
    "#### Max Pooling layer\n",
    "- downscaling by (2x2)\n",
    "- input no of neurons = 32\n",
    "- output no of neurons = 16\n",
    "\n",
    "#### Convolutional layer\n",
    "- 32 filters (3x3)\n",
    "- Activation: ReLU\n",
    "- input no of neurons = 16\n",
    "- output no of neurons = 32\n",
    "\n",
    "#### Max Pooling layer\n",
    "- downscaling by (2x2)\n",
    "- input no of neurons = 32\n",
    "- output no of neurons = 16\n",
    "\n",
    "#### Convolutional layer\n",
    "- 64 filters (3x3)\n",
    "- Activation: ReLU\n",
    "- input no of neurons = 16\n",
    "- output no of neurons = 64\n",
    "\n",
    "#### Max Pooling layer\n",
    "- downscaling by (2x2)\n",
    "- input no of neurons = 64\n",
    "- output no of neurons = 32\n",
    "\n",
    "#### Fully connected layer\n",
    "- 64 neurons\n",
    "- Activation: ReLU\n",
    "- input no of neurons = 32\n",
    "- output no of neurons = 64\n",
    "- dropout = 50%\n",
    "\n",
    "#### Fully connected output layer\n",
    "- 10 neurons\n",
    "- Activation: SoftMax\n",
    "- Input no of neurons = 32\n",
    "- output no of neurons = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3,150,150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64)) # 64 neurons\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) # drop 50% of neurons\n",
    "\n",
    "# output layer: classify to 10 driver's states\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the learning process (Compilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up _*Augmentation Configuration*_ for training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1.0/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling validation images _(no augmentation is applied on validation images as we need to test our model)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating training data\n",
    "- read images from directory data/train\n",
    "- Until we have our training data generating indefininte number of _augmented batches of size = 32_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18574 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory('data/train', target_size=(150,150), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar generator for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3850 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=test_datagen.flow_from_directory('data/test', target_size=(150,150), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the CNN on the training and test set generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Software\\Conda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Software\\Conda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=653, epochs=20, validation_steps=800)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "653/653 [==============================] - 6246s 10s/step - loss: 1.9024 - acc: 0.3151 - val_loss: 1.0371 - val_acc: 0.6535\n",
      "Epoch 2/20\n",
      "653/653 [==============================] - 5424s 8s/step - loss: 1.0610 - acc: 0.6384 - val_loss: 0.4584 - val_acc: 0.8811\n",
      "Epoch 3/20\n",
      "653/653 [==============================] - 5561s 9s/step - loss: 0.7166 - acc: 0.7584 - val_loss: 0.2740 - val_acc: 0.9272\n",
      "Epoch 4/20\n",
      "653/653 [==============================] - 5545s 8s/step - loss: 0.5657 - acc: 0.8148 - val_loss: 0.2052 - val_acc: 0.9477\n",
      "Epoch 5/20\n",
      "653/653 [==============================] - 5792s 9s/step - loss: 0.4891 - acc: 0.8430 - val_loss: 0.1593 - val_acc: 0.9600\n",
      "Epoch 6/20\n",
      "653/653 [==============================] - 5946s 9s/step - loss: 0.4263 - acc: 0.8647 - val_loss: 0.1278 - val_acc: 0.9651\n",
      "Epoch 7/20\n",
      "653/653 [==============================] - 5925s 9s/step - loss: 0.3729 - acc: 0.8807 - val_loss: 0.1172 - val_acc: 0.9727\n",
      "Epoch 8/20\n",
      "653/653 [==============================] - 5421s 8s/step - loss: 0.3584 - acc: 0.8887 - val_loss: 0.0886 - val_acc: 0.9786\n",
      "Epoch 9/20\n",
      "653/653 [==============================] - 5506s 8s/step - loss: 0.3405 - acc: 0.8932 - val_loss: 0.0944 - val_acc: 0.9741\n",
      "Epoch 10/20\n",
      "653/653 [==============================] - 5372s 8s/step - loss: 0.3166 - acc: 0.9027 - val_loss: 0.0843 - val_acc: 0.9800\n",
      "Epoch 11/20\n",
      "653/653 [==============================] - 5133s 8s/step - loss: 0.3045 - acc: 0.9072 - val_loss: 0.0896 - val_acc: 0.9765\n",
      "Epoch 12/20\n",
      "653/653 [==============================] - 5113s 8s/step - loss: 0.3047 - acc: 0.9073 - val_loss: 0.0714 - val_acc: 0.9819\n",
      "Epoch 13/20\n",
      "265/653 [===========>..................] - ETA: 29:51 - loss: 0.3059 - acc: 0.9092"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, samples_per_epoch=20924, nb_epoch=20, validation_data=validation_generator, nb_val_samples=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save generated weights from training to obtain results later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('driver_state_detection_small_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
